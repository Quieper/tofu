{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import string\n",
    "import time\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def word2idx(word):\n",
    "        return word_model.wv.vocab[word].index\n",
    "    def idx2word(idx):\n",
    "        return word_model.wv.index2word[idx]\n",
    "\n",
    "    def sample(preds, temperature=1.0):\n",
    "        if temperature <= 0:\n",
    "            return np.argmax(preds)\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        return np.argmax(probas)\n",
    "\n",
    "    def generate_next(text, num_generated=10):\n",
    "        word_idxs = [word2idx(word) for word in text.lower().split()]\n",
    "        for i in range(num_generated):\n",
    "            prediction = model.predict(x=np.array(word_idxs))\n",
    "            idx = sample(prediction[-1], temperature=0.7)\n",
    "            word_idxs.append(idx)\n",
    "        return ' '.join(idx2word(idx) for idx in word_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching the text...\n"
     ]
    }
   ],
   "source": [
    "print('Fetching the text...')\n",
    "train = pd.read_excel('../../data/sentiment/Train - clean.xlsx')\n",
    "test = pd.read_excel('../../data/sentiment/Test - clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df = df[df.Sentiment.notna()]\n",
    "    return df[df.Text.notna()]\n",
    "\n",
    "train = clean_df(train)\n",
    "test = clean_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the sentences...\n",
      "Num sentences: 3075\n"
     ]
    }
   ],
   "source": [
    "max_sentence_len = 40\n",
    "\n",
    "def prepare(df):\n",
    "    txt = [[word for word in doc.lower().translate(string.punctuation).split()[:max_sentence_len]] for doc in list(df.Text)]\n",
    "    lab = np.array(list(df.Sentiment))\n",
    "    return txt, lab\n",
    "\n",
    "train_txt, train_y = prepare(train)\n",
    "test_txt, test_y = prepare(test)\n",
    "print('\\nPreparing the sentences...')\n",
    "print('Num sentences:', len(train_txt)+len(test_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training word2vec...\n",
      "Result embedding shape: (7977, 100)\n"
     ]
    }
   ],
   "source": [
    "print('\\nTraining word2vec...')\n",
    "word_model = gensim.models.Word2Vec(train_txt+test_txt, size=100, min_count=1, window=5, iter=100)\n",
    "pretrained_weights = word_model.wv.vectors\n",
    "vocab_size, embedding_size = pretrained_weights.shape\n",
    "print('Result embedding shape:', pretrained_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the data for LSTM...\n",
      "train_x shape: (2542, 40)\n",
      "train_y shape: (2542,)\n",
      "test_x shape: (533, 40)\n",
      "test_y shape: (533,)\n"
     ]
    }
   ],
   "source": [
    "print('\\nPreparing the data for LSTM...')\n",
    "def prepare_lstm(txts):\n",
    "    x = np.zeros([len(txts), max_sentence_len], dtype=np.int32)\n",
    "    for i, sentence in enumerate(txts):\n",
    "        for t, word in enumerate(sentence):\n",
    "            x[i, t] = word2idx(word)\n",
    "    return x\n",
    "\n",
    "train_x = prepare_lstm(train_txt)\n",
    "print('train_x shape:', train_x.shape)\n",
    "print('train_y shape:', train_y.shape)\n",
    "\n",
    "test_x = prepare_lstm(test_txt)\n",
    "print('test_x shape:', test_x.shape)\n",
    "print('test_y shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM...\n"
     ]
    }
   ],
   "source": [
    "print('\\nTraining LSTM...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[pretrained_weights]))\n",
    "model.add(LSTM(units=embedding_size, return_sequences=True))\n",
    "model.add(LSTM(units=embedding_size, return_sequences=True))\n",
    "model.add(LSTM(units=embedding_size))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roguehydra/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2542 samples, validate on 533 samples\n",
      "Epoch 1/15\n",
      "2542/2542 [==============================] - 7s 3ms/step - loss: 0.6548 - accuracy: 0.6227 - val_loss: 0.6860 - val_accuracy: 0.5178\n",
      "Epoch 2/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.5816 - accuracy: 0.6888 - val_loss: 0.6459 - val_accuracy: 0.6792\n",
      "Epoch 3/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.5115 - accuracy: 0.7435 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 4/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.4424 - accuracy: 0.7998 - val_loss: 0.5584 - val_accuracy: 0.7598\n",
      "Epoch 5/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.3759 - accuracy: 0.8430 - val_loss: 0.6681 - val_accuracy: 0.7373\n",
      "Epoch 6/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.2942 - accuracy: 0.8808 - val_loss: 0.6570 - val_accuracy: 0.7580\n",
      "Epoch 7/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.2274 - accuracy: 0.9150 - val_loss: 0.6947 - val_accuracy: 0.7786\n",
      "Epoch 8/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.1877 - accuracy: 0.9335 - val_loss: 0.6875 - val_accuracy: 0.7711\n",
      "Epoch 9/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.1340 - accuracy: 0.9559 - val_loss: 0.9113 - val_accuracy: 0.7392\n",
      "Epoch 10/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.1168 - accuracy: 0.9630 - val_loss: 0.9246 - val_accuracy: 0.7580\n",
      "Epoch 11/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.0936 - accuracy: 0.9709 - val_loss: 0.8521 - val_accuracy: 0.7786\n",
      "Epoch 12/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.0852 - accuracy: 0.9736 - val_loss: 0.9769 - val_accuracy: 0.7636\n",
      "Epoch 13/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.0523 - accuracy: 0.9843 - val_loss: 1.0545 - val_accuracy: 0.7636\n",
      "Epoch 14/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.0370 - accuracy: 0.9902 - val_loss: 1.1802 - val_accuracy: 0.7486\n",
      "Epoch 15/15\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 0.0482 - accuracy: 0.9851 - val_loss: 1.3604 - val_accuracy: 0.7430\n",
      "Elapsed time: 72.73\n"
     ]
    }
   ],
   "source": [
    "b = time.time()\n",
    "model.fit(train_x, train_y,\n",
    "          validation_data=(test_x, test_y),\n",
    "          batch_size=128,\n",
    "          epochs=15)\n",
    "e = time.time()\n",
    "print('Elapsed time: {}'.format(round(e-b,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533/533 [==============================] - 0s 731us/step\n",
      "Time elapsed: 0.63s\n",
      "    Accuracy: 74.3%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(test_x, test_y)\n",
    "b = time.time()\n",
    "pred = model.predict(test_x)\n",
    "e = time.time()\n",
    "print('Time elapsed: {}s\\n    Accuracy: {}%'.format(round(e-b,2),round(acc*100,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
