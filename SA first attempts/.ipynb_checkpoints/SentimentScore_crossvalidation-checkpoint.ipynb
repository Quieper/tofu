{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentimentScore(paragraph, weight=1):\n",
    "    sentences = []\n",
    "    lines_list = tokenize.sent_tokenize(paragraph)\n",
    "    sentences.extend(lines_list)\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment = 0\n",
    "    for sentence in sentences:\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        score = ss['compound']\n",
    "        sentiment += score*weight\n",
    "    return sentiment, sentiment/len(sentences)\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_excel('02 Actors - added.xlsx', sheet_name= 'Sheet1')\n",
    "f = f[f.country != 'Mexico']\n",
    "f = f.drop(['keywords', 'Traslation', 'country', 'actor name', 'typology (informant/actor)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  url stance\n",
      "14  https://industry.airliquide.co.za/oil-and-gas/...    pro\n",
      "17  https://www.shell.co.za/about-us/projects-and-...    pro\n",
      "20  http://www.saiia.org.za/opinion-analysis/frack...    pro\n",
      "21  http://www.saoga.org.za/projects/shale-gas-com...    pro\n",
      "27  http://www.saoga.org.za/directory/member-detai...    pro\n",
      "37  https://historicengland.org.uk/advice/planning...    con\n",
      "38  https://www.london.gov.uk/what-we-do/planning/...    con\n",
      "39  https://www.ecotricity.co.uk/our-green-energy/...    con\n",
      "40             http://frack-off.org.uk/fracking-hell/    con\n",
      "41      http://frack-off.org.uk/faq/what-is-fracking/    con\n",
      "42     http://frack-off.org.uk/faq/what-is-shale-gas/    con\n",
      "43  https://friendsoftheearth.uk/climate-change/fr...    con\n",
      "44  https://www.greenpeace.org.uk/what-we-do/clima...    con\n",
      "49  https://www.gov.uk/government/publications/abo...    pro\n",
      "50  https://www.gov.uk/government/news/new-measure...    pro\n",
      "51  http://www.ukoog.org.uk/onshore-extraction/dri...    pro\n",
      "52  https://cuadrillaresources.com/about-fracking/...    pro\n",
      "53  https://www.ineos.com/businesses/ineos-shale/w...    pro\n",
      "56  https://www.quaker.org.uk/our-work/sustainabil...    con\n",
      "58  https://www.gov.uk/government/organisations/de...    pro\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "f['url'] = f['url'].astype('str')\n",
    "f = f[f.stance != 'neutral']\n",
    "mask = f['url'].str.len() > 35\n",
    "f = f.loc[mask]\n",
    "#print(f)\n",
    "f = f.loc[[14,17,20,21,27,37,38,39,40,41,42,43,44,49,50,51,52,53,56,58]]\n",
    "print(f)\n",
    "print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {}\n",
    "for _, article in f.iterrows():\n",
    "    url = article['url']\n",
    "    if 'pdf' not in url:\n",
    "        try:\n",
    "            html = urllib.request.urlopen(url).read()\n",
    "        except:\n",
    "            continue\n",
    "        text = text_from_html(html)\n",
    "        urls[url] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3077217391304348 pro\n",
      "0.5907600000000001 pro\n",
      "0.129331914893617 pro\n",
      "http://www.saiia.org.za/opinion-analysis/fracking-in-south-africa-an-alternative-to-coal\n",
      "0.629075 pro\n",
      "0.36716666666666664 pro\n",
      "0.1790411764705882 con\n",
      "-0.008706250000000013 con\n",
      "0.12427727272727274 con\n",
      "0.13489411764705883 con\n",
      "0.06104999999999999 con\n",
      "0.2389268749999999 pro\n",
      "0.3822636363636364 pro\n",
      "0.21123571428571433 pro\n",
      "0.2863197368421052 pro\n",
      "0.26616874999999995 con\n",
      "https://www.quaker.org.uk/our-work/sustainability/fracking\n",
      "0.29457142857142854 pro\n",
      "14 87.5\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "for _, article in f.iterrows():\n",
    "    url = article['url']\n",
    "    stance = article['stance']\n",
    "    if url in urls.keys():\n",
    "        _, sentiment = SentimentScore(urls[url])\n",
    "        print(sentiment, stance)\n",
    "        if stance == 'con' and sentiment < 0.2 or stance == 'pro' and sentiment > 0.2:\n",
    "            score += 1\n",
    "        #if stance == 'neutral' and sentiment > 0.1 and sentiment < 0.2:\n",
    "        #    score += 1\n",
    "        if stance == 'pro' and sentiment < 0.2 or stance == 'con' and sentiment > 0.2:\n",
    "            print(url)\n",
    "print(score, score/len(urls)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12441188441188442 pro\n",
      "0.12895764366352602 pro\n",
      "0.0981856378915203 pro\n",
      "0.14779411764705883 pro\n",
      "0.02913359788359788 pro\n",
      "0.08225108225108226 con\n",
      "0.10852222134234331 con\n",
      "0.11637834086203655 con\n",
      "0.17167603540737875 con\n",
      "0.12323599754155305 con\n",
      "0.1259144342407941 pro\n",
      "0.09752095422308188 pro\n",
      "0.10388285024154588 pro\n",
      "0.19165858807858804 pro\n",
      "0.10600352843503524 con\n",
      "0.03412698412698413 pro\n",
      "8 50.0\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "for _, article in f.iterrows():\n",
    "    url = article['url']\n",
    "    stance = article['stance']\n",
    "    if url in urls.keys():\n",
    "        sentiment, sub = TextBlob(urls[url]).sentiment\n",
    "        print(sentiment, stance)\n",
    "        if stance == 'con' and sentiment < 0.11 or stance == 'pro' and sentiment > 0.11:\n",
    "            score += 1\n",
    "        #if stance == 'neutral' and sentiment > 0.1 and sentiment < 0.2:\n",
    "        #    score += 1\n",
    "print(score, score/len(urls)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
