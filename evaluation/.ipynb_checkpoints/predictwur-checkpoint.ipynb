{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the predicted labels\n",
    "def analyse_sentiment(article):\n",
    "    paragraphs = [par for par in article.split('\\n') if str(par) != '' and len(par)>75]\n",
    "    sen, raw_sen = sentiment_model.predict(paragraphs)\n",
    "    sen_score = round(sum(sen)/len(sen)*100,1)\n",
    "    return sen_score\n",
    "\n",
    "def analyse_frame(article):\n",
    "    paragraphs = [par for par in article.split('\\n') if str(par) != '' and len(par)>75]\n",
    "    frame, raw_frame = frame_model.predict(paragraphs)\n",
    "    eco, hea, env = get_credible(raw_frame, frame)\n",
    "    return eco, hea, env\n",
    "    \n",
    "# returns the frame scores for confident predictions only\n",
    "def get_credible(raw_f, f):\n",
    "    cred = [f[i] for i in range(len(f)) if raw_f[i][f[i]] > 2]\n",
    "    eco = get_per(cred, 0)\n",
    "    hea = get_per(cred, 1)\n",
    "    env = get_per(cred, 2)\n",
    "    return eco, hea, env\n",
    "\n",
    "# percentage calculater - probably redundant and more easy to do\n",
    "def get_per(l, n):\n",
    "    try:\n",
    "        tmp = round(l.count(n)/len(l)*100,1)\n",
    "    except:\n",
    "        tmp = 0\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "sentiment_model = ClassificationModel(\n",
    "    \"roberta\",\n",
    "    \"../predicting/models/sentiment/RoBERTa/outputs/\",\n",
    "    use_cuda=False\n",
    ")\n",
    "\n",
    "frame_model = ClassificationModel(\n",
    "    \"roberta\",\n",
    "    \"../predicting/models/frame/RoBERTa/outputs/\",\n",
    "    use_cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4664b6137b43afb0fc72479c8aae2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=534.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c556521b477049409af1241b65cbf0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=67.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 89.5%\n"
     ]
    }
   ],
   "source": [
    "# predict sentiment\n",
    "wur_data_sentiment = pd.read_excel('../data/sentiment/Test - clean.xlsx')\n",
    "sentiment_text = wur_data_sentiment.Text\n",
    "sentiment_label = wur_data_sentiment.Sentiment\n",
    "\n",
    "pred_sentiment, _ = sentiment_model.predict(sentiment_text)\n",
    "print('Accuracy: {}%'.format(round(sum([1 for i in range(len(pred_sentiment)) if pred_sentiment[i] == sentiment_label[i]])/len(sentiment_label)*100,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dee908697b47d5944969a50fb2948c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=516.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7f33eb4d604ac2b747f79abeec455e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=65.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 79.5%\n"
     ]
    }
   ],
   "source": [
    "# predict frame\n",
    "wur_data_frame = pd.read_excel('../data/frame/Test - clean.xlsx')\n",
    "frame_text = wur_data_frame.Text\n",
    "frame_label = wur_data_frame.Frame\n",
    "\n",
    "pred_frame, _ = frame_model.predict(frame_text)\n",
    "count = 0\n",
    "for i in range(len(pred_frame)):\n",
    "    if pred_frame[i] == 0 and frame_label[i] == 'economic':\n",
    "        count += 1\n",
    "    elif pred_frame[i] == 1 and frame_label[i] == 'health':\n",
    "        count += 1\n",
    "    elif pred_frame[i] == 2 and 'environment' in frame_label[i]:\n",
    "        count += 1\n",
    "print('Accuracy: {}%'.format(round(count/len(frame_label)*100,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
